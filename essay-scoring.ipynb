{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essay Scoring Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/gdamien/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gdamien/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gdamien/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "#Data Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "import re\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import spacy\n",
    "\n",
    "#Utils\n",
    "import random\n",
    "import os\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import zipfile\n",
    "\n",
    "#Machine Learning\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, Embedding, Dropout, Conv1D, Flatten, Bidirectional\n",
    "from keras import losses\n",
    "from keras.optimizers import SGD, Adam\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "#Data Vizualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('training_set_rel3.tsv', sep='\\t', encoding='latin-1', quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score      ...        \\\n",
       "0             NaN             NaN            NaN      ...         \n",
       "1             NaN             NaN            NaN      ...         \n",
       "2             NaN             NaN            NaN      ...         \n",
       "3             NaN             NaN            NaN      ...         \n",
       "4             NaN             NaN            NaN      ...         \n",
       "\n",
       "   rater2_trait3  rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait2  rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN scores is: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of NaN scores is:\",np.isnan(df_train[\"domain1_score\"]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of essays: 12976\n",
      "Number of essay sets: 8\n"
     ]
    }
   ],
   "source": [
    "#Number of essay sets\n",
    "print(\"Number of essays:\", len(df_train))\n",
    "print(\"Number of essay sets:\", len(set(df_train['essay_set'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAE/CAYAAADhW39vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA5gkSVJn/x8PuG/KBGCgYQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c25832898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_ids = df_train[\"essay_set\"].value_counts().keys().tolist()\n",
    "essays_per_set = df_train[\"essay_set\"].value_counts().values\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(set_ids, essays_per_set)\n",
    "plt.title(\"Number of essays per set.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIgAAAJOCAYAAADcTTxQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIkmSJEmSpJ77/wDk/OeUUjCjpgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c2643b160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for set_id in range(1, 7):\n",
    "    \n",
    "    plt.subplot(2, 3, set_id)\n",
    "    \n",
    "    grades_ids = df_train[\"domain1_score\"][df_train[\"essay_set\"]==set_id].value_counts().keys().tolist()\n",
    "    grades_values = df_train[\"domain1_score\"][df_train[\"essay_set\"]==set_id].value_counts().values\n",
    "\n",
    "    plt.bar(grades_ids, grades_values)\n",
    "    plt.title(\"Distribution of grades of essay set {}.\".format(set_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3EAAAE/CAYAAADouUp5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmSJPWISZwkSZIk9cj/B2gAHd8g7oa5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c25e8dc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "for set_id in range(1, 3):\n",
    "    \n",
    "    plt.subplot(1, 2, set_id)\n",
    "    set_id +=6\n",
    "    \n",
    "    grades_ids = df_train[\"domain1_score\"][df_train[\"essay_set\"]==set_id].value_counts().keys().tolist()\n",
    "    grades_values = df_train[\"domain1_score\"][df_train[\"essay_set\"]==set_id].value_counts().values\n",
    "\n",
    "    plt.bar(grades_ids, grades_values)\n",
    "    plt.title(\"Distribution of grades of essay set {}.\".format(set_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay scored 0:\n",
      "\n",
      "The affects of the cyclist is if it does not change. it cut hurt a lot of people feeling because they @CAPS1 donÂ’t care about the cyclist. IÂ’m one of them people who does not care about it cause it does not affect me or anyone I know. It is a big deal to write people, some of them @CAPS1 blow stuff up. They talking on tiv and on the radio making all this stuff they say is made up. I donÂ’t believe to I see it. That @CAPS1 not for black people because it has not did anything to us. We really donÂ’t care about the affects of the cyclist.\n",
      "\n",
      "Essay scored 10:\n",
      "\n",
      "One day, a few years ago, I woke up and my mom said we were going  to my grandmaÂ’s house. So started to get ready. After I was done getting dressed I looked on.  My dresser and grabbed my @MONEY2 @MONEY3 that I was saving up to buy something just incase we went to the store When we got there I saw my cousinÂ’s dad @CAPS1 walking a puppy. I walked up to him and asked about the dog, he said it was his brothers dog and he was selling it. My mom said I could get a dog so I asked him how much did he coast. @CAPS1 said @MONEY1. I got really excited because I had @MONEY2 and could get @MONEY3 from my granding. So I called my mom but she was busy somewhere else but she told me that she wanted to see the dog before I buy him. So @CAPS1 waited their for hours but my mom took forever. Then finally I got impatience and bought him. But my wow wasnÂ’t mad because she ended up liking him\n",
      "\n",
      "--> The difference in writing style is striking: the latter extract is more grammatically correct, uses conjonction words (but, then, etc.), and have longer sentences.\n"
     ]
    }
   ],
   "source": [
    "#Sample essays\n",
    "print(\"Essay scored 0:\")\n",
    "print()\n",
    "print(df_train[\"essay\"][df_train[\"rater1_domain1\"]==0].tolist()[0])\n",
    "print()\n",
    "print(\"Essay scored 10:\")\n",
    "print()\n",
    "print(df_train[\"essay\"][df_train[\"rater1_domain1\"]==10].tolist()[0])\n",
    "print()\n",
    "print(\"--> The difference in writing style is striking: the latter extract is more grammatically correct, \\\n",
    "uses conjonction words (but, then, etc.), and have longer sentences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We take a subset of the training dataset:\n",
    "df_train = df_train[df_train[\"essay_set\"]==5]\n",
    "df_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_words = set(brown.words())\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "#Number of words\n",
    "def count_words(text):\n",
    "    text = ''.join([w for w in text.lower() if w not in punctuation])\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    count = len(tokens)\n",
    "    return count\n",
    "\n",
    "df_train[\"nb_words\"] = df_train[\"essay\"].apply(count_words)\n",
    "\n",
    "#Number of sentences\n",
    "def count_sentences(text):\n",
    "    sents = nltk.sent_tokenize(text)\n",
    "    count = len(sents)\n",
    "    return count\n",
    "\n",
    "df_train[\"nb_sents\"] = df_train[\"essay\"].apply(count_sentences)\n",
    "\n",
    "#Average sentence length\n",
    "def average_sentence_length(text):\n",
    "    return np.mean([count_words(s) for s in nltk.sent_tokenize(text)])\n",
    "\n",
    "df_train[\"avg_sent_length\"] = df_train[\"essay\"].apply(average_sentence_length)\n",
    "\n",
    "#Number of distinct words\n",
    "def unique_words_ratio(text):\n",
    "    text = ''.join([w for w in text.lower() if w not in punctuation])\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    count = len(set(tokens))\n",
    "    return count / len(tokens)\n",
    "\n",
    "df_train[\"unique_words_ratio\"] = df_train[\"essay\"].apply(unique_words_ratio)\n",
    "\n",
    "#Number of verbs\n",
    "\n",
    "#Number of nouns\n",
    "\n",
    "#Number of prepositions\n",
    "\n",
    "#Number of spelling mistakes\n",
    "def spelling_mistakes_ratio(text):\n",
    "    text = ''.join([w for w in text.lower() if w not in punctuation])\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    spelling_mistakes = len([word for word in tokens if word not in set_words and '@' not in word])\n",
    "    return spelling_mistakes / len(text.split())\n",
    "\n",
    "df_train[\"spelling_mistakes_ratio\"] = df_train[\"essay\"].apply(spelling_mistakes_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>...</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "      <th>nb_words</th>\n",
       "      <th>nb_sents</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>unique_words_ratio</th>\n",
       "      <th>spelling_mistakes_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7079</td>\n",
       "      <td>11827</td>\n",
       "      <td>5</td>\n",
       "      <td>In this memoir of Narciso Rodriguez, @PERSON3'...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132</td>\n",
       "      <td>8</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.098485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7080</td>\n",
       "      <td>11828</td>\n",
       "      <td>5</td>\n",
       "      <td>Throughout the excerpt from Home the Blueprint...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>7</td>\n",
       "      <td>23.857143</td>\n",
       "      <td>0.610778</td>\n",
       "      <td>0.041916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7081</td>\n",
       "      <td>11829</td>\n",
       "      <td>5</td>\n",
       "      <td>The mood the author created in the memoir is l...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>6</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.082569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7082</td>\n",
       "      <td>11830</td>\n",
       "      <td>5</td>\n",
       "      <td>The mood created by the author is showing how ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.169014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7083</td>\n",
       "      <td>11831</td>\n",
       "      <td>5</td>\n",
       "      <td>The mood created in the memoir is happiness an...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127</td>\n",
       "      <td>8</td>\n",
       "      <td>15.875000</td>\n",
       "      <td>0.535433</td>\n",
       "      <td>0.055118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  essay_id  essay_set  \\\n",
       "0   7079     11827          5   \n",
       "1   7080     11828          5   \n",
       "2   7081     11829          5   \n",
       "3   7082     11830          5   \n",
       "4   7083     11831          5   \n",
       "\n",
       "                                               essay  rater1_domain1  \\\n",
       "0  In this memoir of Narciso Rodriguez, @PERSON3'...               2   \n",
       "1  Throughout the excerpt from Home the Blueprint...               2   \n",
       "2  The mood the author created in the memoir is l...               3   \n",
       "3  The mood created by the author is showing how ...               1   \n",
       "4  The mood created in the memoir is happiness an...               2   \n",
       "\n",
       "   rater2_domain1  rater3_domain1  domain1_score  rater1_domain2  \\\n",
       "0               2             NaN              2             NaN   \n",
       "1               2             NaN              2             NaN   \n",
       "2               3             NaN              3             NaN   \n",
       "3               0             NaN              1             NaN   \n",
       "4               3             NaN              3             NaN   \n",
       "\n",
       "   rater2_domain2           ...             rater3_trait2  rater3_trait3  \\\n",
       "0             NaN           ...                       NaN            NaN   \n",
       "1             NaN           ...                       NaN            NaN   \n",
       "2             NaN           ...                       NaN            NaN   \n",
       "3             NaN           ...                       NaN            NaN   \n",
       "4             NaN           ...                       NaN            NaN   \n",
       "\n",
       "   rater3_trait4  rater3_trait5  rater3_trait6  nb_words  nb_sents  \\\n",
       "0            NaN            NaN            NaN       132         8   \n",
       "1            NaN            NaN            NaN       167         7   \n",
       "2            NaN            NaN            NaN       109         6   \n",
       "3            NaN            NaN            NaN        71         3   \n",
       "4            NaN            NaN            NaN       127         8   \n",
       "\n",
       "   avg_sent_length  unique_words_ratio  spelling_mistakes_ratio  \n",
       "0        16.500000            0.621212                 0.098485  \n",
       "1        23.857143            0.610778                 0.041916  \n",
       "2        18.166667            0.724771                 0.082569  \n",
       "3        23.666667            0.591549                 0.169014  \n",
       "4        15.875000            0.535433                 0.055118  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_regex(text):\n",
    "\n",
    "    text = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \\'s\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" \\'ve\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" n\\'t\", text)\n",
    "    text = re.sub(r\"\\'re\", \" \\'re\", text)\n",
    "    text = re.sub(r\"\\'d\", \" \\'d\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" \\'ll\", text)\n",
    "    text = re.sub(r\",\", \" , \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\(\", \" ( \", text)\n",
    "    text = re.sub(r\"\\)\", \" ) \", text)\n",
    "    text = re.sub(r\"\\?\", \" ? \", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    punctuation = set(string.punctuation)\n",
    "    text = ''.join([w for w in text.lower() if w not in punctuation])\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    text = [stemmer.stem(w) for w in text.split()]\n",
    "\n",
    "    # Covenrt list of words to one string\n",
    "    text = ' '.join(w for w in text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Initial text:\n",
      "-------------\n",
      "\n",
      "The mood created by the author is showing how cuban's lived and about Their cultra and how they lived and some people from other cultra's could be diffrent and don't @CAPS1 cared about their cultra's and some people do care about their cultra like narciso parents. that is what the author is trying to say. and that some people should respect their cultra and not @CAPS2 To be a different cultra.\n",
      "\n",
      "-------------\n",
      "Cleaned text:\n",
      "-------------\n",
      "\n",
      "the mood creat by the author is show how cuban s live and about their cultra and how they live and some peopl from other cultra s could be diffrent and do nt caps1 care about their cultra s and some peopl do care about their cultra like narciso parent that is what the author is tri to say and that some peopl should respect their cultra and not caps2 to be a differ cultra\n"
     ]
    }
   ],
   "source": [
    "raw_text = df_train[\"essay\"][df_train[\"rater1_domain1\"]==1].tolist()[0]\n",
    "print(\"-------------\")\n",
    "print(\"Initial text:\")\n",
    "print(\"-------------\")\n",
    "print()\n",
    "print(raw_text)\n",
    "print()\n",
    "\n",
    "\n",
    "clean_text = clean_text_regex(raw_text)\n",
    "print(\"-------------\")\n",
    "print(\"Cleaned text:\")\n",
    "print(\"-------------\")\n",
    "print()\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean essays\n",
    "df_train['clean_essay'] = df_train['essay'].apply(clean_text_regex)\n",
    "\n",
    "#Create TD-IDF vectors\n",
    "tf = TfidfVectorizer(min_df=2, ngram_range=(1,3))\n",
    "train_tfidf_matrix = tf.fit_transform(df_train['clean_essay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df_train[\"domain1_score\"]\n",
    "#df_variables = hstack([csr_matrix(df_train[[\"nb_words\", \"nb_sents\", \"avg_sent_length\", \"unique_words_ratio\", \"spelling_mistakes_ratio\"]].values), train_tfidf_matrix])\n",
    "df_variables = df_train[[\"nb_words\", \"nb_sents\", \"avg_sent_length\", \"unique_words_ratio\", \"spelling_mistakes_ratio\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1444, 5) (361, 5) (1444,) (361,)\n"
     ]
    }
   ],
   "source": [
    "#Create training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_variables, df_labels, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "lr = LogisticRegression(C=1, random_state = 42, class_weight = 'balanced')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix\n",
      " [[ 0  0  0  0  0]\n",
      " [ 6 31 26  0  0]\n",
      " [ 1 15 79 19  0]\n",
      " [ 0  2 25 71 12]\n",
      " [ 0  0  5 35 34]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.65      0.49      0.56        63\n",
      "          2       0.59      0.69      0.63       114\n",
      "          3       0.57      0.65      0.60       110\n",
      "          4       0.74      0.46      0.57        74\n",
      "\n",
      "avg / total       0.62      0.60      0.60       361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nConfusion matrix\\n', confusion_matrix(predictions, y_test))\n",
    "print()\n",
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix\n",
      " [[ 0  1  0  0  0]\n",
      " [ 6 24 15  0  0]\n",
      " [ 1 20 94 21  1]\n",
      " [ 0  2 22 81 15]\n",
      " [ 0  1  4 23 30]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.50      0.53      0.52        45\n",
      "          2       0.70      0.69      0.69       137\n",
      "          3       0.65      0.68      0.66       120\n",
      "          4       0.65      0.52      0.58        58\n",
      "\n",
      "avg / total       0.65      0.63      0.64       361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nConfusion matrix\\n', confusion_matrix(predictions, y_test))\n",
    "print()\n",
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, subsample=0.5)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix\n",
      " [[ 0  2  0  0  0]\n",
      " [ 7 21 17  0  0]\n",
      " [ 0 22 89 22  1]\n",
      " [ 0  2 25 81 21]\n",
      " [ 0  1  4 22 24]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         2\n",
      "          1       0.44      0.47      0.45        45\n",
      "          2       0.66      0.66      0.66       134\n",
      "          3       0.65      0.63      0.64       129\n",
      "          4       0.52      0.47      0.49        51\n",
      "\n",
      "avg / total       0.60      0.60      0.60       361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nConfusion matrix\\n', confusion_matrix(predictions, y_test))\n",
    "print()\n",
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Averaging the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "lr = LogisticRegression(C=1, random_state = 42, class_weight = 'balanced')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "predictions_lr = lr.predict_proba(X_test)\n",
    "\n",
    "#Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predictions_rf = rf.predict_proba(X_test)\n",
    "\n",
    "#XGBoost\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, subsample=0.5)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "predictions_xgb = xgb_model.predict_proba(X_test)\n",
    "\n",
    "#Average of predictions\n",
    "random.seed(9001)\n",
    "rd = np.random.random(3)\n",
    "rd /= 3\n",
    "alpha, beta, gamma = rd[0], rd[1], rd[2]\n",
    "predictions = np.argmax((alpha*predictions_rf + beta*predictions_lr + gamma*predictions_xgb)/3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix\n",
      " [[ 0  2  0  0  0]\n",
      " [ 7 23 18  0  0]\n",
      " [ 0 20 86 23  0]\n",
      " [ 0  2 26 77 20]\n",
      " [ 0  1  5 25 26]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         2\n",
      "          1       0.48      0.48      0.48        48\n",
      "          2       0.64      0.67      0.65       129\n",
      "          3       0.62      0.62      0.62       125\n",
      "          4       0.57      0.46      0.50        57\n",
      "\n",
      "avg / total       0.59      0.59      0.59       361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nConfusion matrix\\n', confusion_matrix(predictions, y_test))\n",
    "print()\n",
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'58.730000000000004%'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(100*np.round(sum([np.abs(p-s)==0 for p,s in zip(predictions, y_test)])/len(predictions), 4)) + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use of Glove word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download(filename):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        filename, _ = urlretrieve(url + filename, filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "url = 'http://nlp.stanford.edu/data/wordvecs/'\n",
    "\n",
    "filename = maybe_download('glove.6B.zip')\n",
    "\n",
    "if not os.path.exists('glove'):\n",
    "    zip_ref = zipfile.ZipFile(filename, 'r')\n",
    "    zip_ref.extractall('glove')\n",
    "    zip_ref.close()\n",
    "    \n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('glove','glove.6B.300d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype ='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_glove_bow = np.zeros((len(df_train), 300))\n",
    "for index in range(len(df_train)):\n",
    "    essay_vector = np.zeros((1, 300))\n",
    "    for word in df_train[\"essay\"][index].split():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            essay_vector += embedding_vector\n",
    "    train_glove_bow[index, :] = essay_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variables = np.hstack([df_train[[\"nb_words\", \"nb_sents\", \"avg_sent_length\", \"unique_words_ratio\", \"spelling_mistakes_ratio\"]].values, train_glove_bow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1624, 300) (181, 300) (1624,) (181,)\n"
     ]
    }
   ],
   "source": [
    "#Create training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_glove_bow, df_labels, test_size=0.1, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "lr = LogisticRegression(C=1, random_state = 42, class_weight = 'balanced')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix\n",
      " [[ 0  2  0  0  0]\n",
      " [ 3  9 18  2  0]\n",
      " [ 0 10 32 14  1]\n",
      " [ 0  1 12 34 12]\n",
      " [ 0  0  3 16 12]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         2\n",
      "          1       0.41      0.28      0.33        32\n",
      "          2       0.49      0.56      0.52        57\n",
      "          3       0.52      0.58      0.54        59\n",
      "          4       0.48      0.39      0.43        31\n",
      "\n",
      "avg / total       0.48      0.48      0.47       181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nConfusion matrix\\n', confusion_matrix(predictions, y_test))\n",
    "print()\n",
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Fully Connected Artificial Neural Network on Bag of Words (average) using Glove word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_doc2vec(df):\n",
    "    doc2vec = np.zeros((len(df_train), 300))\n",
    "    for index in range(len(df_train)):\n",
    "        essay_vector = np.zeros((1, 300))\n",
    "        for word in df[\"essay\"][index].split():\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                essay_vector += embedding_vector\n",
    "        doc2vec[index, :] = essay_vector\n",
    "    return doc2vec\n",
    "\n",
    "train = create_doc2vec(df_train)\n",
    "le = preprocessing.LabelEncoder()\n",
    "labels = le.fit_transform(df_train[\"domain1_score\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1624, 300) (181, 300) (1624,) (181,)\n"
     ]
    }
   ],
   "source": [
    "#Create training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=0.1, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, len(set(labels.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_102 (Dense)            (None, 500)               150500    \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 386,405\n",
      "Trainable params: 386,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1461 samples, validate on 163 samples\n",
      "Epoch 1/50\n",
      "1461/1461 [==============================] - 1s - loss: 1.5285 - mean_squared_error: 0.1539 - acc: 0.3231 - val_loss: 1.4472 - val_mean_squared_error: 0.1490 - val_acc: 0.3374\n",
      "Epoch 2/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.4267 - mean_squared_error: 0.1471 - acc: 0.3498 - val_loss: 1.4303 - val_mean_squared_error: 0.1486 - val_acc: 0.3374\n",
      "Epoch 3/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.4034 - mean_squared_error: 0.1462 - acc: 0.3429 - val_loss: 1.4188 - val_mean_squared_error: 0.1484 - val_acc: 0.3252\n",
      "Epoch 4/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.3845 - mean_squared_error: 0.1447 - acc: 0.3559 - val_loss: 1.4099 - val_mean_squared_error: 0.1482 - val_acc: 0.3436\n",
      "Epoch 5/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.3662 - mean_squared_error: 0.1436 - acc: 0.3593 - val_loss: 1.3928 - val_mean_squared_error: 0.1471 - val_acc: 0.3742\n",
      "Epoch 6/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.3530 - mean_squared_error: 0.1428 - acc: 0.3689 - val_loss: 1.3813 - val_mean_squared_error: 0.1464 - val_acc: 0.3865\n",
      "Epoch 7/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.3498 - mean_squared_error: 0.1428 - acc: 0.3676 - val_loss: 1.3717 - val_mean_squared_error: 0.1458 - val_acc: 0.3620\n",
      "Epoch 8/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.3308 - mean_squared_error: 0.1412 - acc: 0.3669 - val_loss: 1.3640 - val_mean_squared_error: 0.1456 - val_acc: 0.3804\n",
      "Epoch 9/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.3357 - mean_squared_error: 0.1418 - acc: 0.3751 - val_loss: 1.3583 - val_mean_squared_error: 0.1454 - val_acc: 0.3374\n",
      "Epoch 10/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.3075 - mean_squared_error: 0.1392 - acc: 0.3826 - val_loss: 1.3467 - val_mean_squared_error: 0.1445 - val_acc: 0.3865\n",
      "Epoch 11/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.3136 - mean_squared_error: 0.1399 - acc: 0.3895 - val_loss: 1.3426 - val_mean_squared_error: 0.1443 - val_acc: 0.3742\n",
      "Epoch 12/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.3116 - mean_squared_error: 0.1402 - acc: 0.3943 - val_loss: 1.3285 - val_mean_squared_error: 0.1432 - val_acc: 0.3988\n",
      "Epoch 13/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.3110 - mean_squared_error: 0.1402 - acc: 0.3799 - val_loss: 1.3178 - val_mean_squared_error: 0.1422 - val_acc: 0.3865\n",
      "Epoch 14/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.2781 - mean_squared_error: 0.1371 - acc: 0.4278 - val_loss: 1.3152 - val_mean_squared_error: 0.1423 - val_acc: 0.3804\n",
      "Epoch 15/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.2845 - mean_squared_error: 0.1377 - acc: 0.4031 - val_loss: 1.3047 - val_mean_squared_error: 0.1413 - val_acc: 0.3865\n",
      "Epoch 16/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.2809 - mean_squared_error: 0.1382 - acc: 0.3915 - val_loss: 1.2934 - val_mean_squared_error: 0.1405 - val_acc: 0.4049\n",
      "Epoch 17/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.2751 - mean_squared_error: 0.1373 - acc: 0.4120 - val_loss: 1.2897 - val_mean_squared_error: 0.1405 - val_acc: 0.3742\n",
      "Epoch 18/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.2596 - mean_squared_error: 0.1357 - acc: 0.4162 - val_loss: 1.2812 - val_mean_squared_error: 0.1398 - val_acc: 0.4049\n",
      "Epoch 19/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.2592 - mean_squared_error: 0.1359 - acc: 0.4100 - val_loss: 1.2876 - val_mean_squared_error: 0.1406 - val_acc: 0.3804\n",
      "Epoch 20/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.2580 - mean_squared_error: 0.1361 - acc: 0.4052 - val_loss: 1.2711 - val_mean_squared_error: 0.1391 - val_acc: 0.3988\n",
      "Epoch 21/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.2592 - mean_squared_error: 0.1362 - acc: 0.4237 - val_loss: 1.2540 - val_mean_squared_error: 0.1377 - val_acc: 0.4110\n",
      "Epoch 22/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.2418 - mean_squared_error: 0.1349 - acc: 0.4264 - val_loss: 1.2428 - val_mean_squared_error: 0.1369 - val_acc: 0.4294\n",
      "Epoch 23/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.2243 - mean_squared_error: 0.1330 - acc: 0.4319 - val_loss: 1.2444 - val_mean_squared_error: 0.1368 - val_acc: 0.3926\n",
      "Epoch 24/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.2217 - mean_squared_error: 0.1327 - acc: 0.4415 - val_loss: 1.2205 - val_mean_squared_error: 0.1346 - val_acc: 0.4294\n",
      "Epoch 25/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.2154 - mean_squared_error: 0.1326 - acc: 0.4264 - val_loss: 1.2323 - val_mean_squared_error: 0.1359 - val_acc: 0.4110\n",
      "Epoch 26/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.2211 - mean_squared_error: 0.1332 - acc: 0.4278 - val_loss: 1.2279 - val_mean_squared_error: 0.1354 - val_acc: 0.3988\n",
      "Epoch 27/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.2001 - mean_squared_error: 0.1310 - acc: 0.4394 - val_loss: 1.2156 - val_mean_squared_error: 0.1343 - val_acc: 0.3926\n",
      "Epoch 28/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1891 - mean_squared_error: 0.1292 - acc: 0.4661 - val_loss: 1.1979 - val_mean_squared_error: 0.1324 - val_acc: 0.4356\n",
      "Epoch 29/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1675 - mean_squared_error: 0.1280 - acc: 0.4689 - val_loss: 1.2064 - val_mean_squared_error: 0.1337 - val_acc: 0.4110\n",
      "Epoch 30/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1813 - mean_squared_error: 0.1291 - acc: 0.4600 - val_loss: 1.1889 - val_mean_squared_error: 0.1319 - val_acc: 0.4294\n",
      "Epoch 31/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1785 - mean_squared_error: 0.1296 - acc: 0.4476 - val_loss: 1.1926 - val_mean_squared_error: 0.1325 - val_acc: 0.4356\n",
      "Epoch 32/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1533 - mean_squared_error: 0.1266 - acc: 0.4750 - val_loss: 1.1950 - val_mean_squared_error: 0.1326 - val_acc: 0.4049\n",
      "Epoch 33/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1420 - mean_squared_error: 0.1256 - acc: 0.4860 - val_loss: 1.1835 - val_mean_squared_error: 0.1314 - val_acc: 0.3988\n",
      "Epoch 34/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1457 - mean_squared_error: 0.1264 - acc: 0.4750 - val_loss: 1.1601 - val_mean_squared_error: 0.1292 - val_acc: 0.4663\n",
      "Epoch 35/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1543 - mean_squared_error: 0.1274 - acc: 0.4730 - val_loss: 1.1725 - val_mean_squared_error: 0.1305 - val_acc: 0.4724\n",
      "Epoch 36/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1324 - mean_squared_error: 0.1259 - acc: 0.4682 - val_loss: 1.1551 - val_mean_squared_error: 0.1284 - val_acc: 0.4785\n",
      "Epoch 37/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1324 - mean_squared_error: 0.1256 - acc: 0.4661 - val_loss: 1.1513 - val_mean_squared_error: 0.1287 - val_acc: 0.4294\n",
      "Epoch 38/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1384 - mean_squared_error: 0.1268 - acc: 0.4606 - val_loss: 1.1403 - val_mean_squared_error: 0.1278 - val_acc: 0.4601\n",
      "Epoch 39/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1234 - mean_squared_error: 0.1250 - acc: 0.4812 - val_loss: 1.1364 - val_mean_squared_error: 0.1277 - val_acc: 0.4540\n",
      "Epoch 40/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1118 - mean_squared_error: 0.1237 - acc: 0.4894 - val_loss: 1.1593 - val_mean_squared_error: 0.1297 - val_acc: 0.4601\n",
      "Epoch 41/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1121 - mean_squared_error: 0.1238 - acc: 0.4771 - val_loss: 1.1449 - val_mean_squared_error: 0.1286 - val_acc: 0.4601\n",
      "Epoch 42/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1314 - mean_squared_error: 0.1261 - acc: 0.4784 - val_loss: 1.1179 - val_mean_squared_error: 0.1257 - val_acc: 0.4601\n",
      "Epoch 43/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1147 - mean_squared_error: 0.1246 - acc: 0.4716 - val_loss: 1.1239 - val_mean_squared_error: 0.1262 - val_acc: 0.4724\n",
      "Epoch 44/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.0984 - mean_squared_error: 0.1226 - acc: 0.5038 - val_loss: 1.1200 - val_mean_squared_error: 0.1258 - val_acc: 0.4601\n",
      "Epoch 45/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.0977 - mean_squared_error: 0.1227 - acc: 0.4976 - val_loss: 1.1232 - val_mean_squared_error: 0.1263 - val_acc: 0.4601\n",
      "Epoch 46/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.0901 - mean_squared_error: 0.1219 - acc: 0.5017 - val_loss: 1.1245 - val_mean_squared_error: 0.1265 - val_acc: 0.4724\n",
      "Epoch 47/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1028 - mean_squared_error: 0.1238 - acc: 0.4887 - val_loss: 1.1114 - val_mean_squared_error: 0.1255 - val_acc: 0.4540\n",
      "Epoch 48/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.0792 - mean_squared_error: 0.1210 - acc: 0.5031 - val_loss: 1.1101 - val_mean_squared_error: 0.1256 - val_acc: 0.4601\n",
      "Epoch 49/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.1009 - mean_squared_error: 0.1240 - acc: 0.4702 - val_loss: 1.1101 - val_mean_squared_error: 0.1250 - val_acc: 0.4601\n",
      "Epoch 50/50\n",
      "1461/1461 [==============================] - 0s - loss: 1.0748 - mean_squared_error: 0.1209 - acc: 0.5051 - val_loss: 1.0816 - val_mean_squared_error: 0.1224 - val_acc: 0.4724\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Dense(500, activation='tanh', input_dim=300))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(300, activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(200, activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(len(set(labels.tolist())), activation='softmax'))\n",
    "print(model.summary())\n",
    "# compile network\n",
    "# Compile the model\n",
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd , metrics=['mean_squared_error','accuracy'])\n",
    "# fit network\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, batch_size=32, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix\n",
      " [[ 0  0  0  0  0]\n",
      " [ 3  9  8  0  0]\n",
      " [ 0 12 31 19  1]\n",
      " [ 0  1 26 46 24]\n",
      " [ 0  0  0  1  0]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.41      0.45      0.43        20\n",
      "          2       0.48      0.49      0.48        63\n",
      "          3       0.70      0.47      0.56        97\n",
      "          4       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.58      0.48      0.52       181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "print('\\nConfusion matrix\\n', confusion_matrix(predictions, y_test))\n",
    "print()\n",
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. One-layer RNN (GRU) on word sequences using Glove word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5052 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "vocabularySize = 10000\n",
    "tokenizer = Tokenizer(num_words = vocabularySize, filters = '!\"#$%&()*+,-./:;<=>?@\\\\^_`{|}~\\t\\n')\n",
    "\n",
    "tokenizer.fit_on_texts(df_train[\"essay\"].tolist())\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index)+1,300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of an essay is: 416\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = max([len(s.split()) for s in df_train[\"essay\"].tolist()])\n",
    "print(\"Maximum length of an essay is:\", max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_dataset(max_seq_length=max_seq_length):\n",
    "    sequences = tokenizer.texts_to_sequences(df_train[\"essay\"].tolist())\n",
    "    sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='pre')\n",
    "    return sequences\n",
    "\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "train = create_train_dataset(max_seq_length=max_seq_length)\n",
    "le = preprocessing.LabelEncoder()\n",
    "labels = le.fit_transform(df_train[\"domain1_score\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1624, 416) (181, 416) (1624,) (181,)\n"
     ]
    }
   ],
   "source": [
    "#Create training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=0.1, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, len(set(labels.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 416, 300)          1515900   \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 256)               427776    \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 50)                12850     \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 1,956,781\n",
      "Trainable params: 440,881\n",
      "Non-trainable params: 1,515,900\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1461 samples, validate on 163 samples\n",
      "Epoch 1/10\n",
      "1461/1461 [==============================] - 56s - loss: 1.5685 - mean_squared_error: 0.1567 - acc: 0.2902 - val_loss: 1.5491 - val_mean_squared_error: 0.1553 - val_acc: 0.3129\n",
      "Epoch 2/10\n",
      "1461/1461 [==============================] - 60s - loss: 1.5500 - mean_squared_error: 0.1552 - acc: 0.3210 - val_loss: 1.5295 - val_mean_squared_error: 0.1537 - val_acc: 0.3313\n",
      "Epoch 3/10\n",
      "1461/1461 [==============================] - 59s - loss: 1.5310 - mean_squared_error: 0.1537 - acc: 0.3450 - val_loss: 1.5126 - val_mean_squared_error: 0.1524 - val_acc: 0.3313\n",
      "Epoch 4/10\n",
      "1461/1461 [==============================] - 57s - loss: 1.5147 - mean_squared_error: 0.1524 - acc: 0.3518 - val_loss: 1.4974 - val_mean_squared_error: 0.1513 - val_acc: 0.3436\n",
      "Epoch 5/10\n",
      "1461/1461 [==============================] - 58s - loss: 1.5001 - mean_squared_error: 0.1513 - acc: 0.3566 - val_loss: 1.4851 - val_mean_squared_error: 0.1504 - val_acc: 0.3313\n",
      "Epoch 6/10\n",
      "1461/1461 [==============================] - 55s - loss: 1.4878 - mean_squared_error: 0.1504 - acc: 0.3580 - val_loss: 1.4742 - val_mean_squared_error: 0.1496 - val_acc: 0.3497\n",
      "Epoch 7/10\n",
      "1461/1461 [==============================] - 58s - loss: 1.4770 - mean_squared_error: 0.1496 - acc: 0.3580 - val_loss: 1.4650 - val_mean_squared_error: 0.1490 - val_acc: 0.3497\n",
      "Epoch 8/10\n",
      "1461/1461 [==============================] - 57s - loss: 1.4675 - mean_squared_error: 0.1489 - acc: 0.3539 - val_loss: 1.4571 - val_mean_squared_error: 0.1484 - val_acc: 0.3620\n",
      "Epoch 9/10\n",
      "1461/1461 [==============================] - 59s - loss: 1.4593 - mean_squared_error: 0.1483 - acc: 0.3504 - val_loss: 1.4504 - val_mean_squared_error: 0.1480 - val_acc: 0.3620\n",
      "Epoch 10/10\n",
      "1461/1461 [==============================] - 57s - loss: 1.4521 - mean_squared_error: 0.1478 - acc: 0.3498 - val_loss: 1.4446 - val_mean_squared_error: 0.1477 - val_acc: 0.3558\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], input_length=max_seq_length, trainable=False))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(GRU(256))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(len(set(labels.tolist())), activation='softmax'))\n",
    "print(model.summary())\n",
    "# compile network\n",
    "optimizer = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#optimizer = Adam(lr=0.01) #SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['mean_squared_error','accuracy'])\n",
    "# fit network\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, batch_size=64, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix\n",
      " [[ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 1 23 45 34 18]\n",
      " [ 3  8 15 20 12]\n",
      " [ 0  0  1  1  0]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.74      0.37      0.49       121\n",
      "          3       0.36      0.34      0.35        58\n",
      "          4       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.61      0.36      0.44       181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "print('\\nConfusion matrix\\n', confusion_matrix(predictions, y_test))\n",
    "print()\n",
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. One layer BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 416, 300)          1515900   \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 416, 200)          320800    \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 2,078,505\n",
      "Trainable params: 562,605\n",
      "Non-trainable params: 1,515,900\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1461 samples, validate on 163 samples\n",
      "Epoch 1/10\n",
      "1461/1461 [==============================] - 96s - loss: 1.5905 - mean_squared_error: 0.1586 - acc: 0.2834 - val_loss: 1.5970 - val_mean_squared_error: 0.1590 - val_acc: 0.2638\n",
      "Epoch 2/10\n",
      "1461/1461 [==============================] - 91s - loss: 1.5782 - mean_squared_error: 0.1575 - acc: 0.3053 - val_loss: 1.5842 - val_mean_squared_error: 0.1580 - val_acc: 0.2699\n",
      "Epoch 3/10\n",
      "1461/1461 [==============================] - 89s - loss: 1.5653 - mean_squared_error: 0.1565 - acc: 0.3217 - val_loss: 1.5719 - val_mean_squared_error: 0.1570 - val_acc: 0.2270\n",
      "Epoch 4/10\n",
      "1461/1461 [==============================] - 89s - loss: 1.5530 - mean_squared_error: 0.1555 - acc: 0.3217 - val_loss: 1.5605 - val_mean_squared_error: 0.1560 - val_acc: 0.2515\n",
      "Epoch 5/10\n",
      "1461/1461 [==============================] - 89s - loss: 1.5418 - mean_squared_error: 0.1546 - acc: 0.3244 - val_loss: 1.5499 - val_mean_squared_error: 0.1552 - val_acc: 0.2393\n",
      "Epoch 6/10\n",
      "1461/1461 [==============================] - 89s - loss: 1.5312 - mean_squared_error: 0.1537 - acc: 0.3306 - val_loss: 1.5402 - val_mean_squared_error: 0.1544 - val_acc: 0.2577\n",
      "Epoch 7/10\n",
      "1461/1461 [==============================] - 89s - loss: 1.5215 - mean_squared_error: 0.1530 - acc: 0.3251 - val_loss: 1.5312 - val_mean_squared_error: 0.1537 - val_acc: 0.2699\n",
      "Epoch 8/10\n",
      "1461/1461 [==============================] - 103s - loss: 1.5124 - mean_squared_error: 0.1523 - acc: 0.3402 - val_loss: 1.5228 - val_mean_squared_error: 0.1531 - val_acc: 0.2945\n",
      "Epoch 9/10\n",
      "1461/1461 [==============================] - 92s - loss: 1.5040 - mean_squared_error: 0.1516 - acc: 0.3457 - val_loss: 1.5150 - val_mean_squared_error: 0.1525 - val_acc: 0.3313\n",
      "Epoch 10/10\n",
      "1461/1461 [==============================] - 89s - loss: 1.4961 - mean_squared_error: 0.1510 - acc: 0.3498 - val_loss: 1.5079 - val_mean_squared_error: 0.1520 - val_acc: 0.3252\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], input_length=max_seq_length, trainable=False))\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=True)))#, input_shape=(5, 10)))\n",
    "model.add(Bidirectional(LSTM(100)))\n",
    "model.add(Dense(len(set(labels.tolist())), activation='softmax'))\n",
    "print(model.summary())\n",
    "# compile network\n",
    "optimizer = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#optimizer = Adam(lr=0.01) #SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['mean_squared_error','accuracy'])\n",
    "# fit network\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, batch_size=64, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix\n",
      " [[ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 1  3 10  6  2  0]\n",
      " [ 2  5 71 74  5  1]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.12      0.45      0.19        22\n",
      "          3       0.93      0.47      0.62       158\n",
      "          4       0.00      0.00      0.00         0\n",
      "          5       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.83      0.47      0.57       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "print('\\nConfusion matrix\\n', confusion_matrix(predictions, y_test))\n",
    "print()\n",
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
